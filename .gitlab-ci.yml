image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3.7-alpine

services:
  - ${ARTIFACTORY_SERVER}/dockerhub-remote/docker:dind


stages:
  - lint-tests
  - smoke-tests
  - release_test_prep
  - sprinkle-tests
  - droplets
  - publish
  - release

variables:
  GIT_SUBMODULE_STRATEGY: recursive

# validate README file(s) only contain links that respond with 200 OK
run_link_checker:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:10
  stage: smoke-tests
  tags:
    - docker-executor
  only:
    refs:
      # the current intent is to run only on main and release branches
      - main
      - /^R.*/
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - make link_check
  allow_failure: true

# lint
lint_generator:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3.7-alpine
  stage: lint-tests
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - cd template-generator
    - pip install -r requirements.txt
    - make lint

# validate the template generator 'source' file(s) are always in sync with the
# generated content - i.e. running 'make all' after checking out a stable branch
# should never result in different generated content
run_generator_and_validate_no_diff:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/python:3.7-alpine
  stage: smoke-tests
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - apk add --no-cache git
    - apk add libffi-dev
    - cd template-generator
    - pip3 install -r requirements.txt
    - python template_generator/main.py --azure
    - if git diff | grep 'diff --git'; then exit 1; else exit 0; fi


# run template generator smoke tests - validate file contents, etc.
run_smoke_tests:
  stage: smoke-tests
  tags:
    - docker-executor
  except:
    refs:
      - schedules
      - triggers
      - pipelines
    variables:
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  script:
    - apk add --no-cache build-base
    - apk add --no-cache bash
    - make run_smoke_tests

pre_release_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    refs:
      - main
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
    refs:
      - schedules
      - triggers
      - pipelines
  variables:
    TEST_POLICY: automated-test-scripts/data/test_policies/azure_pre_release_test.yaml
    STACK_TYPE: dewdrop-preproduction
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

post_release_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    - schedules
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
      - $RELEASE_RUNTIME_INIT_TESTS == "true"
  variables:
    TEST_POLICY: automated-test-scripts/data/test_policies/post_release_test.yaml
    STACK_TYPE: dewdrop-preproduction
  # Added a manual trigger for now so that this job doesn't get triggered after every commit
  when: manual
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

scheduled_test_job:
  stage: sprinkle-tests
  tags:
    - docker-executor
  only:
    - schedules
  except:
    variables:
      - $ANALYTICS_MESSAGE_PROCESS == "true"
      - $ANALYTICS_SCRIPTS_PROCESS == "true"
      - $VERIFY_REGKEY_COUNT == "true"
      - $REAPER_RUN == "true"
      - $DAILY_TESTS_MONITOR == "true"
  variables:
    TEST_POLICY: set in schedule!
    STACK_TYPE: dewdrop-production
  script:
    - pip install -r cloud-tools/master-job/requirements.txt
    - cloud-tools/master-job/sprinkler.py --test-plan $TEST_POLICY --token $CI_JOB_TOKEN --branch $CI_COMMIT_REF_NAME --stack-type $STACK_TYPE --project-id $CI_PROJECT_ID
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure


# This job gets triggered by the sprinkler.py script that get ran by the 'master_test_job' it ingests TEMPLATE_URL
# and TEMPLATE_PARAMETERS which are passed down by the sprinkler.py script. Using the variables runs dewdrop with
# the set environment variables
dewdrop_test_run:
  image: ${ARTIFACTORY_SERVER}/ecosystems-cloudsolutions-docker-dev/dewdrop:$DEWDROP_IMAGE_ID
  stage: droplets
  tags:
    - docker-executor
  variables:
    SSH_KEY: "$SSH_KEY"
    AZURE_TENANT_ID: "$AZURE_TENANT_ID"
    AZURE_CLIENT_ID: "$AZURE_CLIENT_ID"
    AZURE_SERVICE_PRINCIPAL: "$AZURE_SERVICE_PRINCIPAL"
    AZURE_SUBSCRIPTION_ID: "$AZURE_SUBSCRIPTION_ID"
    TEMPLATE_URL: "$TEMPLATE_URL"
    TEMPLATE_PARAMETERS: "$TEMPLATE_PARAMETERS"
    STACK_TYPE: "$STACK_TYPE"
    GITLAB_JOB_URL: "$CI_JOB_URL"
  only:
    variables:
      - $RUN_SCHEDULED_DEWDROP_TEST == "true"
  script:
    # the dewdrop image itself does not contain any test files, so ensure dewdrop
    # is run from the known location where test policies expect it to be
    # location: root of the cloud factory repository
    - if [ "$CLOUD_PROVIDER_ENVIRONMENT" == "aws_china" ]; then
    -   AWS_DEFAULT_REGION=$AWS_CHINA_DEFAULT_REGION
    -   AWS_ACCESS_KEY_ID=$AWS_CHINA_ACCESS_KEY_ID
    -   AWS_SECRET_ACCESS_KEY=$AWS_CHINA_SECRET_ACCESS_KEY
    - fi
    - python /dewdrop/dewdrop-docker.py

publish_to_github:
  image: ${ARTIFACTORY_SERVER}/dockerhub-remote/node:8
  stage: release
  only:
    - /(^publish-(v\d*[1-9]*\.)(\d*[1-9]*\.)(\d).(\d))/
  script:
    # install jq
    - apt-get update
    - apt-get install -y jq
    # Execute Release script to push source to github repo
    - ./cloud-tools/release-tool/publish_github.sh "$ALLOWED_DIRS" "$ALLOWED_FILES"
  variables:
    ALLOWED_DIRS: ".github experimental images supported"
    ALLOWED_FILES: ".gitignore README.md azure-bigip-version-matrix.md azure-offer-list.yaml azure-timezone-list.md azure-update-bigip-image.md bigip-12-note.md iapp-migration.md slack-channel-statement.md template-index.md"
    GITLAB_API_URL: "$AZURE_URL"
    GITHUB_API_TOKEN: "$AZURE_GITHUB_API_TOKEN"
    GITLAB_PRIVATE_TOKEN: "$AZURE_GITLAB_API_TOKEN"
